<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Portfolio Details</title>
    <link href="assets/img/OIP (1).jpeg" rel="icon">
    <link href="assets/css/blogs.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="breadcrumbs">
            <a href="index.html">Home</a> / <a href="testblog.html">Blogs</a> / <span>Chatbot</span>
        </div>
        <h1>YOUR COMPANION - an AI chatbot</h1>
        <p>In this blog,  Let's understand how i built the chatbot and deployed it into AWS cloud</p>
    </header>
    <div class="dropdown">
        <div class="dropdown-title">Contents</div>
        <div class="dropdown-content">
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#Langchain&AmazonTitan">Langchain and Amazon Titan</a></li> 
                <li><a href="#fastAPI">Fast API</a></li>
                <li><a href="#Docker">Docker Image and container</a></li>
                <li><a href="#modeldevelopment">Model development</a></li>
              </ul>        
            </div>
    </div> 
    <main>
        <section class="portfolio-details">
            <div class="container">
                <div class="main-content">
                    <div class="portfolio-description">
                        <h2 id="machenelearning">Introduction</h2>
                        <p>Your companion is an AI chatbot, which is built for a portfolio website. the working of chatbot involve gathering the user information by asking the questions like "your good name?" and "describe your purpose?", then information is sent AWS Dynamodb through API GateWay and AWS Lambda. then the additional Questions from the user with the information user provided initially which is also is stored in a short term memory is then sent as input to Amazon titan LLM From Bedrocks by using Langchain. then LLM process process the input then response is displayed on the chatbot.</p>
                        <p>Every thing until this is fine and works well on our local system. but real challenge occurs when we need to present the same thing to public Webpage. so here is where the Aws comes into picture and we need to deploy our chatbot in a real-time environment. firstly AWS Bedrocks and Langchain needs to be implemented with Fast API. then here comes Docker where a Docker image is bult for Fast API application . then this Docker Image is deployed into EC2 instance which is running on AWS. the public url given by EC2 then integrated to API gateway so we can push and get response. then API gateway deployed URL is then used in frontend application, to get responses. coming to the data storage this is basically through AWS Lambda and Dynamodb. Where API gateway link is generated to AWS Lambda and DynamoDB integration and used in frontend application.</p>
                        <div class="image-container">
                            <div class="image-item">
                                <img src="assets/img/chatbotblog/chatbotworkflow.png" alt="fig 1">
                                <p class="image-description">fig 1 : work flow</p>
                            </div>
                        </div>
                        <h2 id="Langchain&AmazonTitan">Langchain and Amazon Titan</h2>
                        <p>Langchain is a framework that allows users to build applications with LLMs. It's collection of tools simples building generative AI applications featuring access to multiple LLMs like OpenAI, Huggingface, Bedrocks, Lalma etc.</p>
                        <h4>Features of Langchain</h4>
                        <ul>
                            <li><p>Model interaction</p></li>
                            <li><p>Data storage and retrieval</p></li>
                            <li><p>Memory</p></li>
                            <li><p>Agents</p></li>
                            <li><p>chains</p></li>
                        </ul>
                        <a href="https://github.com/langchain-ai/langchain"><p style="color: #007bff;">Have a look at this for more information</p></a>
                        <h4>Role of langchain</h4>
                        <p>As Lanchain simplifies accesing llm's, such that i am using langchain to access <strong style="color: #007bff;"><a href="https://aws.amazon.com/bedrock/">Bedrocks</a></strong> . Bedrocks is a service provided by AWS where we host and find pretrained LLM's. we are using <strong style="color: #007bff;"><a href="https://aws.amazon.com/bedrock/amazon-models/titan/">Amazon Titan</a></strong> as our LLM for this project. AmazonTitan is a popular LLM which is Trained on wide range of data, we can use it as out GPT. For a over view Langchin allows you to access LLM/s present in the Bedrocks so we are choosing Amazon Titan.</p>

                        <div class="code-box" id="codeBox"><button class="copy-btn" onclick="copyCode()">Copy</button>
<pre><code  class="language-python">from langchain.llms.bedrock import Bedrock

model = Bedrock(
    credentials_profile_name="default",  # AWS credentials profile
    region_name="us-east-1",
    model_id="amazon.titan-text-premier-v1:0",  # Amazon Bedrock model
    model_kwargs={
        "temperature": 0.9,
    },
)
response = custom_llm.invoke(input="What is the recipe of mayonnaise?")
print(responce)
</code></pre></div>
                        <p>Som people might not have AWS account and find it vary difficult to access Bedrocks. so we can also use <a href="https://huggingface.co/blog/langchain"><strong style="color: #007bff;">Huggingface & Langchain</strong></a> intigration this is more simpler approach or we canalso impliment Some of the populer LLMs like OpenAi and Lalma directly from langchiain. vist <a></a> directly from here <a href="https://github.com/langchain-ai/langchain/tree/master/docs/docs/integrations/llms"><strong style="color: #007bff;">Langchain Intigrations</strong></a></p>
                        <p>Make sure you visit <a href="https://github.com/langchain-ai/langchain/tree/master/docs/docs/integrations/llms" style="font-size: 25px; color: #007bff;">Here</a>. every integration is documented</p>
                        <p>**Before you run the code AWS credentials needs to be connected, the reason behand <strong>credentials_profile_name=default</strong> is the credentials are already stored in a default profile and to do that follow <a href="https://medium.com/@simonazhangzy/connect-vs-code-to-aws-87e274e5cd4" style="color: #007bff; font-size: 20px;">this steps</a> this can also help you if you what to access more bedrocks models</p>
                        <p><strong> model_id="amazon.titan-text-premier-v1:0"</strong> i am using Amazon Titan but you can use any other LLMs. you just need to change the model_ID and a list of different model ids are available in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html" style="font-size: 20px; color: #007bff;">Here</a> you can chose from pool of different LLMs.</p>
                        <p>model_kwargs are Hyper parameters for the model. where we can able adjust the temperature, max_tokens, min_tokens.stop_sequence etc..</p>
                        <p><SS>custom_llm.invoke(input="What is the recipe of mayonnaise?")</SS> you can change the input as you want to get the response accordingly.</p>
                        <h2 id="fastAPI">FAST API</h2>
                        <blockquote>
                            <p>FastAPI is a modern, high-performance web framework for building APIs with Python 3.7+ based on standard Python type hints</p>
                            <cite>FastAPI</cite>
                        </blockquote>
                        <p>as we seen earlier we are using LangChain and Titan integration get the responses to our prompts which are sent using python. But for any Realtime projects it has to be sent through an webpage but though webpage we cant directly access this all code manually. as webpage uses HTML/CSS and we use python for communication. this is where <SS>API</SS> comes into picture. API's can be accessed through any platforms such as HTML/JS/react to post and get the information. API is not a code it is a link that can be accessed easily.</p>
                        <p>I am using FastAPI for building an API for the Langchain & Bedrocks integration. if we give the input as a prompt to the API then it will give us back the output. this pigmentation is done using <SS>Fast API</SS>.</p>
                        <p><SS>Fast API</SS> gives you lot of flexibility to build high performing API's in user most easy implementation techniques for production environments. </p>
                        <div class="code-box" id="codeBox"><button class="copy-btn" onclick="copyCode()">Copy</button>
                            <pre><code  class="language-python">from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain.llms.bedrock import Bedrock
import uvicorn


app = FastAPI()


app.add_middleware(
    CORSMiddleware,#0563bb90
    allow_origins=["*"],  # Replace "*" with specific allowed origins in production
    allow_credentials=True,
    allow_methods=["*"],  # Allow all HTTP methods, including OPTIONS
    allow_headers=["*"],  # Allow all headers
)


def demo_chatbot():
    model = Bedrock(
        credentials_profile_name="default",  # AWS credentials profile
        region_name="us-east-1",
        model_id="amazon.titan-text-premier-v1:0",  # Amazon Bedrock model
        model_kwargs={
            "temperature": 0.9,
            # "max_tokens_to_sample": 50,
            # "stop": ["\n\n\n"]
        },
    )
    return model

# Define the request schema
class ChatRequest(BaseModel):
    message: str

# Define the chat endpoint
@app.post("/chat")
async def chat(chat_request: ChatRequest):
    print(chat_request)
    user_message = chat_request.message
    if not user_message.strip():
        raise HTTPException(status_code=400, detail="Message cannot be empty.")

    try:
        # Generate a response from the chatbot model
        model = demo_chatbot()
        response = model.predict(user_message)
        return {"reply": response}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An error occurred: {str(e)}")

# Health check endpoint
@app.get("/")
async def read_root(request: Request):
    return {"message": "Hello, World!"}



if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=5000) </code></pre></div>
                        <p><SS>demo_chatbot</SS> is a function used to access the <SS>AmazonTitan</SS> model. which is previously explained already</p>
                        <p> as you run the code and your server is running on  <SS>http://127.0.0.1:5000/</SS> and it is the home address of your server, but your chat bot is actually running on <SS>http://127.0.0.1:5000/chat</SS> where you can post the request and get the response. because as you look at the code the function demo_chatbot() is being called in the route <SS>@app.post("/chat")</SS> and this route is handling the POST request.</p>
                        <p><ss>app.add_middleware</ss> this is one of the most important step when you are using the API for real time deployment. because it allows all the origins, methods and headers. it basically allows you to make cross-origin requests.</p>
                        <p><SS>ChatRequest(BaseModel)</SS> pydantic is one of the Special library that is used to validate the data that is being sent to the API. that means it make sure that the data is in the correct format. in our case it has to be string.</p>
                        <p><SS>async def</SS> if you would like to know the difference the difference between def and async def , its vary simple async def parallelly process the requests you make and def serially process the requests. understand it with an - <al href="https://fastapi.tiangolo.com/async/"> interesting example </al>. and rest is just behave as a function witch return the model response by calling demo_chatbot</p>
                        <div class="image-container">
                            <div class="image-item">
                                <video controls>
                                    <source src="assets/img/chatbotblog/fastapi.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                                <p class="image-description">Follow the steps</p>
                            </div>
                        </div>
                        <SS>This is one way of testing your Fast API, else you can also follow this code to test if the API is perfectly running</SS>
                        <div class="code-box" id="codeBox"><button class="copy-btn" onclick="copyCode()">Copy</button>
<pre><code  class="language-python">import requests
url = 'http://127.0.0.1:5000/chat/'
data = {'message': "hello, how are you"}
# headers = {'Content-type': 'application/json'}
response = requests.post(url, json= data)
print(response.content)
</code></pre></div>
                        <p>If You could get a response, that means your Fast API is working fine and you built an API for your local system. you could not share the link/IP you got by running the python code. because it is your local computer IP address. just you can access because it is running on your local system. to make it access by public computer it needs to be running on the cloud. to do this we need to dockerize the fast api file and deploy it on the cloud and make it run always. so that every one can access it.</p>
                        <h2 id="Docker">Docker Image & Container</h2>
                    </div>
                </div>
                <aside class="portfolio-info">
                    <hedding>Project Information</hedding>
                    <br>
                    <br>
                    <ul>
                        <li><strong>Name:</strong>How do machine learn</li>
                        <li><strong>writer:</strong>Chinnolla Koteshwar</li>
                        <li><strong>Date:</strong> 07 December, 2024</li>
                        <li><strong>URL:</strong> <a href="https://koteshwarchinnolla.github.io/portfolio-koteshwar/">koteshwar portfolio</a></li>
                    </ul>
                    <a href="index.html" class="visit-button">Visit Website</a>
                    <br>
                    <br>
                    <br>
                    <div class="suggestion-box">
                        <h3>Leave a Suggestion</h3>
                        <textarea placeholder="Enter your suggestions here..."></textarea>
                        <button type="submit" class="submit-button">Submit</button>
                    </div>
                </aside>
            </div>
        </section>
    </main>

    <footer>
        <a href="#top" class="scroll-top">üîù</a>
    </footer>
</body>
</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
<script>
    function copyCode() {
        const codeBox = document.querySelector("#codeBox code");
        const codeText = codeBox.innerText.trim(); // Get the code text
        navigator.clipboard.writeText(codeText)
            .then(() => alert("Code copied to clipboard!"))
            .catch(err => alert("Failed to copy code: " + err));
    }
    document.addEventListener("DOMContentLoaded", () => {
    const dropdowns = document.querySelectorAll(".dropdown");

    dropdowns.forEach(dropdown => {
        const title = dropdown.querySelector(".dropdown-title");

        title.addEventListener("click", () => {
            // Toggle active class for the clicked dropdown
            dropdown.classList.toggle("active");

            // Optionally close other dropdowns (uncomment below)
            // dropdowns.forEach(d => {
            //     if (d !== dropdown) d.classList.remove("active");
            // });
        });
    });
});

</script>